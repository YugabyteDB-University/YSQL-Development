{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Setup steps\n",
    "Here are the steps to setup this lab:\n",
    "- Install missing dependencies and restart the notebook\n",
    "- Create the notebook variables\n",
    "- Create the `db_ybu` database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install missing dependencies and restart the notebook\n",
    "Run the following cell to ensure that the notebook dependencies are available. \n",
    "Once run, the proceeding cell doesn't need to be executed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql\n",
    "!pip install psycopg2-binary\n",
    "!pip install sqlalchemy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create the notebook variables \n",
    "\n",
    "> IMPORTANT!\n",
    "> \n",
    "> Do NOT skip running this cell. \n",
    "> \n",
    "\n",
    "The following Python cell creates and stores variables that all the notebooks in this lab will use. You can view these variables in the Jupyter tab.\n",
    "\n",
    "- To run the script, select Execute Cell (Play Arrow) in the left gutter of the cell.\n",
    "- Verify the accuracy of the output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Env variables for Notebook\n",
    "import os\n",
    "\n",
    "# read env_vars.env\n",
    "env_vars = !cat env_vars.env\n",
    "for var in env_vars:\n",
    "    key, value = var.split('=')\n",
    "    os.environ[key] = value\n",
    " \n",
    "\n",
    "# Comment out Local\n",
    "MY_YB_PATH=os.environ.get('MY_YB_PATH_LOCAL')\n",
    "MY_GITPOD_WORKSPACE_URL=os.environ.get('MY_GITPOD_WORKSPACE_URL_LOCAL')\n",
    "MY_SUDO=os.environ.get('MY_SUDO')\n",
    "\n",
    "# Gitpod specific\n",
    "# MY_YB_PATH=os.environ.get('MY_YB_PATH')\n",
    "# MY_GITPOD_WORKSPACE_URL=os.environ.get('GITPOD_WORKSPACE_URL')\n",
    "\n",
    "# env_vars defines the following\n",
    "MY_DB_NAME=os.environ.get('MY_DB_NAME')\n",
    "MY_HOST_IPv4_01=os.environ.get('MY_HOST_IPv4_01')\n",
    "MY_HOST_IPv4_02=os.environ.get('MY_HOST_IPv4_02')\n",
    "MY_HOST_IPv4_03=os.environ.get('MY_HOST_IPv4_03')\n",
    "MY_TSERVER_WEBSERVER_PORT=os.environ.get('MY_TSERVER_WEBSERVER_PORT')\n",
    "MY_DATA3_DDL_FILE=os.environ.get('MY_DATA3_DDL_FILE')\n",
    "MY_DATA3_DML_FILE=os.environ.get('MY_DATA3_DML_FILE')\n",
    "MY_UTIL_FUNCTIONS_FILE=os.environ.get(\"MY_UTIL_FUNCTIONS_FILE\")\n",
    "MY_UTIL_YBTSERVER_METRICS_FILE=os.environ.get(\"MY_UTIL_YBTSERVER_METRICS_FILE\")\n",
    "MY_SUDO=os.environ.get('MY_SUDO')\n",
    "# Current directory of project and related child folders\n",
    "MY_NOTEBOOK_DIR=os.getcwd()\n",
    "MY_NOTEBOOK_DATA_FOLDER=MY_NOTEBOOK_DIR +'/data'\n",
    "MY_NOTEBOOK_UTILS_FOLDER=MY_NOTEBOOK_DIR + '/utils'\n",
    "\n",
    "print(MY_NOTEBOOK_DATA_FOLDER, MY_NOTEBOOK_UTILS_FOLDER)\n",
    "# Store the note book values for other notebooks to use\n",
    "\n",
    "%store MY_DB_NAME\n",
    "%store MY_YB_PATH\n",
    "%store MY_GITPOD_WORKSPACE_URL\n",
    "%store MY_HOST_IPv4_01\n",
    "%store MY_HOST_IPv4_02\n",
    "%store MY_HOST_IPv4_03\n",
    "%store MY_NOTEBOOK_DIR\n",
    "%store MY_TSERVER_WEBSERVER_PORT\n",
    "%store MY_NOTEBOOK_DATA_FOLDER\n",
    "%store MY_NOTEBOOK_UTILS_FOLDER\n",
    "%store MY_DATA3_DDL_FILE\n",
    "%store MY_DATA3_DML_FILE\n",
    "%store MY_UTIL_FUNCTIONS_FILE\n",
    "%store MY_UTIL_YBTSERVER_METRICS_FILE\n",
    "%store MY_SUDO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_SUDO\"  # ifconfig aliases\n",
    "MY_SUDO=${1}\n",
    "\n",
    "if ifconfig lo0 | grep 127.0.0.[2-7] > /dev/null\n",
    "then\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.2\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.3\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.4\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.5\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.6\n",
    "    echo ${MY_SUDO} | sudo -S ifconfig lo0 delete 127.0.0.7\n",
    "fi\n",
    "\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.2\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.3\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.4\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.5\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.6\n",
    "echo ${MY_SUDO} | sudo -S ifconfig lo0 alias 127.0.0.7\n",
    "\n",
    "echo ${MY_SUDO} | sudo ifconfig lo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_TSERVER_WEBSERVER_PORT\"  # yb-ctl create\n",
    "YB_PATH=${1}\n",
    "TSERVER_WEBSERVER_PORT=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "### Grep port 9000 for conflict\n",
    "# lsof -nP -iTCP -sTCP:LISTEN | grep 9000\n",
    "\n",
    "# Stop running cluster\n",
    "if  pgrep -x \"yb-tserver\" > /dev/null \n",
    "then\n",
    "    ./bin/yb-ctl stop\n",
    "    sleep 1\n",
    "fi\n",
    "\n",
    "# Destroy cluster\n",
    "if echo `./bin/yb-ctl status` | grep \"Node Count\"  > /dev/null \n",
    "then\n",
    "    ./bin/yb-ctl destroy\n",
    "    sleep 1\n",
    "fi\n",
    "\n",
    "# Create cluster\n",
    "./bin/yb-ctl --rf 3 create --tserver_flags \"yb_num_shards_per_tserver=1,ysql_num_shards_per_tserver=1,ysql_beta_features=true,webserver_port=\"${TSERVER_WEBSERVER_PORT}  \\\n",
    "--master_flags \"yb_num_shards_per_tserver=1,ysql_num_shards_per_tserver=1\" \\\n",
    "--num_shards_per_tserver=1  \\\n",
    "--placement_info \"cloud1.region1.zone1,cloud2.region2.zone2,cloud3.region3.zone3\" \n",
    "\n",
    "# Output status\n",
    "./bin/yb-ctl status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create the `db_ybu` database with `ysqlsh`\n",
    "Run the following cell to connect to the local host using `ysqlsh`, create the `db_ybu` database, and then list the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  # create database\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# drop and create\n",
    "./bin/ysqlsh -d yugabyte -c \"drop database if exists \"${DB_NAME}\";\"  \n",
    "./bin/ysqlsh -d yugabyte -c \"create database \"${DB_NAME}\";\" \n",
    "\n",
    "# list dbs\n",
    "./bin/ysqlsh -d yugabyte -c \"\\l\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create a partitioned table, add associated partitions, and load data using DDL and DML scripts\n",
    "In this section of the notebook, you will:\n",
    "- Create tables with a DDL script\n",
    "- Load data with a DML script\n",
    "- Verify the creation of tables and data\n",
    "- View the DDL for order_changes\n",
    "- Create Partition Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "##### Create tables, load data, and review relations\n",
    "Run the following cell to execute the DDL and DML scripts using `ysqlsh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" \"$MY_NOTEBOOK_DATA_FOLDER\" \"$MY_DATA3_DDL_FILE\" \"$MY_DATA3_DML_FILE\"   # Order_changes Partition Table\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "DATA_FOLDER=${3}\n",
    "DATA_DDL_FILE=${4}\n",
    "DATA_DML_FILE=${5}\n",
    "\n",
    "ORDER_DDL_PATH=${DATA_FOLDER}/${DATA_DDL_FILE}\n",
    "ORDER_DML_PATH=${DATA_FOLDER}/${DATA_DML_FILE}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# DDL file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DDL_PATH} >&/dev/null\n",
    "sleep 1;\n",
    "\n",
    "# DML file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DML_PATH} >&/dev/null\n",
    "sleep 1;\n",
    "\n",
    "# Describe relations\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "##### View Table Definitions\n",
    "Run the following cell using `ysqlsh` to view a table definition.\n",
    "\n",
    "> Note\n",
    "> \n",
    "> SQL magic does not support PostgreSQL `psql` commands. In order to execute `psql` commands, the notebook uses `bash` and `ysqlsh`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\dt\"\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_2022_02\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_2022_03\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Connect to YugabyteDB using the PostgreSQL Driver for Python\n",
    "The following cells requires:\n",
    "- Python 3.8+ and psycopg2\n",
    "- SQLAlchemy\n",
    "\n",
    "Create a connection string to connect to YugabyteDB through the Python application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%config SqlMagic.autocommit=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Connect to db_ybu\n",
    "import psycopg2\n",
    "import sqlalchemy as alc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# env_var.env\n",
    "db_host=MY_HOST_IPv4_01\n",
    "db_name=MY_DB_NAME\n",
    "\n",
    "connection_str='postgresql+psycopg2://yugabyte@'+db_host+':5433/'+db_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Load SQL magic extension\n",
    ">IMPORTANT!\n",
    ">\n",
    "> To use SQL magic, you must run the following cell that loads the notebook extension.\n",
    "> \n",
    "The connection string is used to create a connection for SQL Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "# creates connection for sql magic\n",
    "%sql {connection_str}\n",
    "#### Verify Table DDL DML operations\n",
    "Run the cell below to view the row counts for the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Partitions\n",
    "\n",
    "Note that in the following result sets, you can see that the attribute, `change_date`, determines the partition location. The virtual table doesn't store data, but the partitions do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM order_changes\n",
    "-- SELECT * FROM order_changes_2022_03\n",
    "-- SELECT * FROM order_changes_2022_02\n",
    "-- SELECT * FROM order_changes_default\n",
    "-- SELECT * FROM order_changes_2022_04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexed Relations\n",
    "\n",
    "By creating an index on the partitioned or parent table, a matching index is also created on any partitions that exist now or in the future. An index or unique constraint declared on a partitioned table is “virtual” in the same way that the partitioned table is: the actual data is in child indexes on the individual partition tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE INDEX ON order_changes (change_date);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Maintenance\n",
    "\n",
    "It is common to have a dynamic set of partitions that define a table. Partitions are frequently dropped and created to dispose of old information and add new info. \n",
    "\n",
    "Partitions simplify the removal of old data with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE order_changes_2022_02;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, a partition can be removed from the partitioned table, but still retain access to the data. This is incase a report or aggregation of the data is necessary.\n",
    "\n",
    "This is done by detaching the partition from the partitioned table with the following statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS order_changes_2022_04;\n",
    "\n",
    "CREATE TABLE order_changes_2022_04 PARTITION OF order_changes FOR VALUES FROM ('2022-04-01') TO ('2022-05-01');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO order_changes VALUES(4, 4001, '2022-04-11', 'add drink');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d+\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_2022_04\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- SELECT * FROM order_changes\n",
    "SELECT * FROM order_changes_2022_04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces and Geo Row Partitioning\n",
    "\n",
    "In a distributed cloud-native database such as YugabyteDB, the location of tables and indexes plays a very important role in achieving optimal performance for any workload.\n",
    "\n",
    "Given the impact of distance on node-to-node communication, it is highly useful to be able to specify at a table level, how its data should be spread across the cluster. This way, you can move tables closer to their clients and decide which tables actually need to be geo-distributed. \n",
    "\n",
    "\n",
    "In the section, we will first create a table that will be split on the geo_partition attribute, which holds that value of a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS transactions;\n",
    "\n",
    "CREATE TABLE transactions (\n",
    "  user_id       INT NOT NULL,\n",
    "  account_id\t  INT NOT NULL,\n",
    "  geo_partition TEXT,\n",
    "  account_type  TEXT NOT NULL,\n",
    "  amount        NUMERIC NOT NULL,\n",
    "  created_at    TIMESTAMP DEFAULT NOW()\n",
    ") PARTITION BY LIST (geo_partition);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces\n",
    "\n",
    "YSQL Tablespaces are entities that can specify the number of replicas for a set of tables or indexes, and how each of these replicas should be distributed across a set of cloud, regions, zones.\n",
    "\n",
    "In the following demo, we will create tablespaces that are designated to a specific location, determined by the placement block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE tblspace_us WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud1\", \"region\": \"region1\", \"zone\": \"zone1\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE tblspace_eu WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud2\", \"region\": \"region2\", \"zone\": \"zone2\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE tblspace_ap WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud3\", \"region\": \"region3\", \"zone\": \"zone3\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\db+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bash is used to process a psql command to view the tablespaces.\n",
    "psql — PostgreSQL interactive terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Partitions\n",
    "\n",
    "When the partitions are created, the tablespaces are connected to assign the geo location. The partitions include the range of values that are accepted for the partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Partition transactions_us - US */\n",
    "\n",
    "CREATE TABLE transactions_us PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('US') TABLESPACE tblspace_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Partition transactions_eu - EU */\n",
    "\n",
    "CREATE TABLE transactions_eu PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('EU') TABLESPACE tblspace_eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Partition transactions_ap - India */\n",
    "\n",
    "CREATE TABLE transactions_ap PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('India') TABLESPACE tblspace_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add records to the transactions table\n",
    "\n",
    "Note that a new data row is filtered by the `geo_partition` attribute to a specific table partition. Since the table partition's tablespace is assigned to a geographic location, offering data residency that complies with regulatory requirements imposed on information based on the data laws that govern a country or region in which the data resides. For example think about the user data stored at Tik Tok and the regulatory standards that prevent that data being stored outside the US border.\n",
    "\n",
    "Data localization also has a role in performance as well. Keeping the data source closer to the client will reduce network latency, improving the response time of the database. Having an understanding of what data is needed where coupled with the ability to place data in particular location is an important tool in distributed sql systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO transactions  VALUES (1, 100, 'US', 'customer', 100, now());\n",
    "INSERT INTO transactions  VALUES (2, 200, 'EU', 'customer', 200, now());\n",
    "INSERT INTO transactions  VALUES (3, 300, 'India', 'customer', 300, now());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate SQL operations\n",
    "\n",
    "Review the rows to compare how the `geo_location` attribute determines the table partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM transactions\n",
    "-- SELECT * FROM transactions_us\n",
    "-- SELECT * FROM transactions_eu\n",
    "-- SELECT * FROM transactions_ap\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition FROM transactions\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition  FROM transactions_us\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition FROM transactions_eu\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition  FROM transactions_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Identifiers\n",
    "\n",
    "Object identifiers (OIDs) are used internally by PostgreSQL as primary keys for various system tables. OIDs are not added to user-created tables, unless WITH OIDS is specified when the table is created, or the default_with_oids configuration variable is enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "# All done!\n",
    "In this lab, you completed the following:\n",
    "\n",
    "- Setup\n",
    "  - Created the `db_ybu` database with `ysqlsh`\n",
    "  - Created tables and loaded data using DDL and DML scripts\n",
    "  - Connected to the database using a PostgreSQL driver for Python\n",
    "  - Created a partitioned table\n",
    "  - Created tablespaces\n",
    "  - Created a geo located row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3.9.4': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0857ffcb80af2fb548f76c195b67e2e5b75e102946b97bbf401092901016b64a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
