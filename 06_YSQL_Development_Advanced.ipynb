{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%; background-color: #000041\"><a target=\"_blank\" href=\"http://university.yugabyte.com\"><img src=\"assets/YBU_Logo.png\" /></a></div>\n",
    "\n",
    "> **YugabyteDB YSQL Development**\n",
    ">\n",
    "> Enroll for free at [Yugabyte University](https://university.yugabyte.com/).\n",
    ">\n",
    "# Advanced language features\n",
    "In this notebook, you'll see how YSQL implements table partitioning and extends this using tablespaces so that developers can build geo-distributed applications that support row-level, geo-partitioning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Requirements\n",
    "Here are the requirements for this notebook:\n",
    "- âœ… Create the notebook variables in `01_Lab_Setup.ipynb`, which you previously did\n",
    "- âœ… Create the `ds_ybu` database, which you previously did\n",
    "- â˜‘ï¸ Import the notebook variables, *which you must do next*\n",
    "- â˜‘ï¸ Connect to the `ds_ybu` database, *which you must do next*\n",
    "- â˜‘ï¸ Complete the following sections\n",
    "  -  Table Partitioning\n",
    "  -  Tablespaces and Row-Level Geo-Partitioning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "## ðŸ‘£ Setup steps\n",
    "Here are the steps to setup this lab:\n",
    "- Import the notebook variables\n",
    "- Connect to `db_ybu` database\n",
    "- Load the SQL Magic extension for the connection\n",
    "- Create the prepared statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the notebook variables \n",
    "\n",
    "> â€¼ï¸ Important\n",
    "> \n",
    "> Do **NOT** skip running the following cell. \n",
    "> \n",
    "\n",
    "The following Python cell reads the stored variables created in the `01_Lab_Setup.ipynb` notebook. To run the script, select Execute Cell (Play Arrow) in the left gutter of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspiration from https://medium.com/analytics-vidhya/postgresql-integration-with-jupyter-notebook-deb97579a38d\n",
    "# Use %store -r to read 01_Lab_Requirements_Setup variables\n",
    "%store -r MY_DB_NAME\n",
    "%store -r MY_YB_PATH\n",
    "%store -r MY_YB_PATH_DATA\n",
    "%store -r MY_GITPOD_WORKSPACE_URL\n",
    "%store -r MY_HOST_IPv4_01\n",
    "%store -r MY_HOST_IPv4_02\n",
    "%store -r MY_HOST_IPv4_03\n",
    "\n",
    "%store -r MY_TSERVER_WEBSERVER_PORT\n",
    "%store -r MY_YB_MASTER_HOST_GITPOD_URL\n",
    "%store -r MY_YB_TSERVER_HOST_GITPOD_URL\n",
    "\n",
    "%store -r MY_NOTEBOOK_DIR\n",
    "%store -r MY_NOTEBOOK_DATA_FOLDER\n",
    "%store -r MY_NOTEBOOK_UTILS_FOLDER\n",
    "\n",
    "%store -r MY_DATA_DDL_FILE_1\n",
    "%store -r MY_DATA_DML_FILE_1\n",
    "%store -r MY_DATA_DDL_FILE_2\n",
    "%store -r MY_DATA_DML_FILE_2\n",
    "%store -r MY_DATA_DDL_FILE_3\n",
    "%store -r MY_DATA_DML_FILE_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the `db_ybu` database\n",
    "Run all the cells in this section:\n",
    "- Connect using Python and PostgreSQL driver\n",
    "- Load the SQL magic extension\n",
    "- Create the prepared statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect using Python and PostgreSQL driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect use Python 3.7.9+\n",
    "import psycopg2\n",
    "import sqlalchemy as alc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "db_host=MY_HOST_IPv4_01\n",
    "db_name=MY_DB_NAME\n",
    "\n",
    "connection_str='postgresql+psycopg2://yugabyte@'+db_host+':5433/'+db_name\n",
    "\n",
    "# engine = create_engine(connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SQL magic extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "\n",
    "# SQL magic for python connection string\n",
    "%sql {connection_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the prepared statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> IMPORTANT!\n",
    ">   \n",
    "> In order to create the prepared statements for the SQL magic connection, you must run the following cell!!!\n",
    "> \n",
    "> Do not skip this step.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% python, but prepared statements as sql magic\n",
    "if (MY_GITPOD_WORKSPACE_URL is None):\n",
    "    a = %sql select fn_yb_create_stmts()\n",
    "else:\n",
    "    WORKSPACE_URL = MY_GITPOD_WORKSPACE_URL.replace('https://','https://7000-')\n",
    "    a = %sql select fn_yb_create_stmts(:WORKSPACE_URL)\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the following query returns a count of 3 (for three prepared statements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "select count(*) from pg_prepared_statements where 1=1 and name in ('stmt_util_metrics_snap_tablet','stmt_util_metrics_snap_table','stmt_util_metrics_snap_reset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Table Partitioning\n",
    "Partitioning is another term for physically dividing large tables in YugabyteDB into smaller, more manageable tables to improve performance. Typically, tables with columns containing timestamps are subject to partitioning because of the historical and predictable nature of their data.\n",
    "\n",
    "Because partitioned tables do not appear nor act differently from the original table, applications accessing the database are not always aware of table partitioning.\n",
    "\n",
    "YSQL supports the following types of partitioning:\n",
    "\n",
    "- *Range partitioning*<br> when a table is partitioned into ranges defined by one or more key columns. In this case, the ranges of values assigned to partitions do not overlap.\n",
    "\n",
    "- *List partitioning*<br> when a table is partitioned via listing key values to appear in each partition.\n",
    "\n",
    "- *Hash partitioning*<br> when a table is partitioned by specifying a modulus and remainder for each partition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q1 | Table partitioning by range\n",
    "In this section of the notebook, you will:\n",
    "- Create tables with a DDL script\n",
    "- Load data with a DML script\n",
    "- Verify the creation of tables and data\n",
    "- View the DDL for `order_changes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "##### Create tables, load data, and review relations\n",
    "Run the following cell to execute the DDL and DML scripts using `ysqlsh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" \"$MY_NOTEBOOK_DATA_FOLDER\" \"$MY_DATA_DDL_FILE_3\" \"$MY_DATA_DML_FILE_3\"   # tbl_order_changes\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "DATA_FOLDER=${3}\n",
    "DATA_DDL_FILE=${4}\n",
    "DATA_DML_FILE=${5}\n",
    "\n",
    "ORDER_DDL_PATH=${DATA_FOLDER}/${DATA_DDL_FILE}\n",
    "ORDER_DML_PATH=${DATA_FOLDER}/${DATA_DML_FILE}\n",
    "\n",
    "echo $ORDER_DDL_PATH\n",
    "echo $ORDER_DML_PATH\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# DDL file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DDL_PATH} >&/dev/null\n",
    "sleep 1;\n",
    "\n",
    "# DML file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DML_PATH} >&/dev/null\n",
    "sleep 1;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" \"$MY_NOTEBOOK_DATA_FOLDER\" \"$MY_DATA_DDL_FILE_3\" \"$MY_DATA_DML_FILE_3\"   # tbl_order_changes\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "\n",
    "# Describe tables\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d public.tbl_order_*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select '' _\n",
    "  , tableoid::regclass\n",
    "  , user_id \n",
    "  , account_id\n",
    "  , change_date\n",
    "  , description\n",
    "from \n",
    "  tbl_order_changes\n",
    "-- tbl_order_changes_prtn_2023_01\n",
    "-- tbl_order_changes_prtn_2023_02\n",
    "-- tbl_order_changes_prtn_2023_03\n",
    "-- tbl_order_changes_prtn_2023_04\n",
    "-- tbl_order_changes_prtn_default\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the Table details in the YB-Master web ui\n",
    "In your web browser, open the following URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% python, but prepared statements as sql magic\n",
    "#THIS_TABLE_NAME='tbl_order_changes'\n",
    "THIS_TABLE_NAME='tbl_order_changes_prtn_2023_01'\n",
    "WORKSPACE_URL = MY_GITPOD_WORKSPACE_URL.replace('https://','https://7000-')\n",
    "view_url = %sql select fn_get_table_id(:WORKSPACE_URL,8200,:THIS_TABLE_NAME) as open_this_url_in_your_web_browser ;\n",
    "\n",
    "print (view_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q1a | View the data distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* explain plan */\n",
    "select '' _\n",
    "  , yb_hash_code( user_id::int, change_date::date ) as pk_hash_code\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x0000, 0x5555)'::text) as col_0x0000_0x5555\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x5555, 0xAAAA)'::text) as col_0x5555_0xAAAA\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0xAAAA, 0xFFFF)'::text) as col_0xAAAA_0xFFFF\n",
    "  , tableoid::regclass\n",
    "  , user_id \n",
    " -- , account_id\n",
    "  , change_date\n",
    " -- , description\n",
    "from \n",
    "tbl_order_changes\n",
    "-- tbl_order_changes_prtn_2023_01\n",
    "-- tbl_order_changes_prtn_2023_02\n",
    "-- tbl_order_changes_prtn_2023_03\n",
    "-- tbl_order_changes_prtn_2023_04\n",
    "-- tbl_order_changes_prtn_default\n",
    "where 1=1 \n",
    "-- and user_id=1\n",
    "-- and change_date >= '2023-01-01' and  change_date <= '2023-01-31'\n",
    "-- and change_date >= '2023-02-01' and  change_date <= '2023-02-28'\n",
    "-- and change_date >= '2023-03-01' and  change_date <= '2023-03-31'\n",
    "and change_date >= '2023-04-01' and  change_date <= '2023-04-30'\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* explain plan */\n",
    "execute stmt_util_metrics_snap_reset;\n",
    "explain (analyze, costs off, verbose, timing on) \n",
    "select '' _\n",
    "  , yb_hash_code( user_id::int, change_date::date ) as pk_hash_code\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x0000, 0x5555)'::text) as col_0x0000_0x5555\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x5555, 0xAAAA)'::text) as col_0x5555_0xAAAA\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0xAAAA, 0xFFFF)'::text) as col_0xAAAA_0xFFFF\n",
    "  , tableoid::regclass\n",
    "  , user_id \n",
    " -- , account_id\n",
    "  , change_date\n",
    " -- , description\n",
    "from \n",
    "tbl_order_changes\n",
    "-- tbl_order_changes_prtn_2023_01\n",
    "-- tbl_order_changes_prtn_2023_02\n",
    "-- tbl_order_changes_prtn_2023_03\n",
    "-- tbl_order_changes_prtn_2023_04\n",
    "-- tbl_order_changes_prtn_default\n",
    "where 1=1 \n",
    "-- and user_id=1\n",
    "-- and change_date >= '2023-01-01' and  change_date <= '2023-01-31'\n",
    "-- and change_date >= '2023-02-01' and  change_date <= '2023-02-28'\n",
    "-- and change_date >= '2023-03-01' and  change_date <= '2023-03-31'\n",
    "and change_date >= '2023-04-01' and  change_date <= '2023-04-20'\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q1b | Explain Plan (above ^^)\n",
    "Some observations:\n",
    "-  `-> Seq Scan on public.tbl_order_changes_prtn_2023_04 (actual time=1.743..2.517 rows=4 loops=1)`\n",
    "\n",
    "\n",
    "> Note: \n",
    ">\n",
    "> If using a default partition, there is an additional scan. This is a known issue and has to do with that a primary key is not created on the default partition.\n",
    "> - `-> Seq Scan on public.tbl_order_changes_prtn_default (actual time=2.196..2.196 rows=0 loops=1)`\n",
    ">   -   `Rows Removed by Filter: 1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "execute stmt_util_metrics_snap_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexed Relations\n",
    "\n",
    "By creating an index on the partitioned or parent table, a matching index is also created on any partitions that exist now or in the future. An index or unique constraint declared on a partitioned table is â€œvirtualâ€ in the same way that the partitioned table is: the actual data is in child indexes on the individual partition tables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the index on the table for `change_date`, the predicate reference in the previous query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop index if exists idx_order_changes_range;\n",
    "create index if not exists idx_order_changes_range on tbl_order_changes (change_date desc);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the explain plain to see how the query planner uses the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* explain plan */\n",
    "execute stmt_util_metrics_snap_reset;\n",
    "explain (analyze, costs off, verbose, timing on) \n",
    "select '' _\n",
    "  , yb_hash_code( user_id::int, change_date::date ) as pk_hash_code\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x0000, 0x5555)'::text) as col_0x0000_0x5555\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0x5555, 0xAAAA)'::text) as col_0x5555_0xAAAA\n",
    "  , fn_find_hash_code_in_partition_hex_range(yb_hash_code( user_id::int, change_date::date ),'hash_split: [0xAAAA, 0xFFFF)'::text) as col_0xAAAA_0xFFFF\n",
    "  , tableoid::regclass\n",
    "  , user_id \n",
    " -- , account_id\n",
    "  , change_date\n",
    " -- , description\n",
    "from \n",
    "tbl_order_changes\n",
    "-- tbl_order_changes_prtn_2023_01\n",
    "-- tbl_order_changes_prtn_2023_02\n",
    "-- tbl_order_changes_prtn_2023_03\n",
    "-- tbl_order_changes_prtn_2023_04\n",
    "-- tbl_order_changes_prtn_default\n",
    "where 1=1 \n",
    "-- nd user_id=1\n",
    "-- and change_date >= '2023-01-01' and  change_date <= '2023-01-31'\n",
    "-- and change_date >= '2023-02-01' and  change_date <= '2023-02-28'\n",
    "-- and change_date >= '2023-03-01' and  change_date <= '2023-03-31'\n",
    "and change_date >= '2023-04-01' and  change_date <= '2023-04-20'\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the metrics related to this query that uses the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "execute stmt_util_metrics_snap_table;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics (above ^^)\n",
    "Here, the index partition is accessed once, and all three related tables partitions are then accessed.\n",
    "\n",
    "| row_name| \trocksdb_number_db_seek | \trocksdb_number_db_next | \n",
    "|--|--|--|\n",
    "| db_ybu tbl_order_changes_prtn_2023_04 link_table_id tablet_id_unq_1\t | 2 | \t5 |\n",
    "| db_ybu tbl_order_changes_prtn_2023_04 link_table_id tablet_id_unq_2\t| 1\t| 2 |\n",
    "| db_ybu tbl_order_changes_prtn_2023_04 link_table_id tablet_id_unq_3\t| 1\t| 2 |\n",
    "| db_ybu tbl_order_changes_prtn_2023_04_change_date_idx  link_table_id tablet_id_unq_4\t| 1\t| 3 |\n",
    "\n",
    "Question:\n",
    "- Why is there only one index partition for the partitioned table?\n",
    "\n",
    "Answer:\n",
    "- The index uses range sharding! A tablet for a user table or index with a partition key using range starts with just one tablet leader on a single node, and as it grows will split into two tablets, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select pg_get_indexdef('idx_order_changes_range':: regclass);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" \"$MY_NOTEBOOK_DATA_FOLDER\" \"$MY_DATA_DDL_FILE_3\" \"$MY_DATA_DML_FILE_3\"   # tbl_order_changes\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# Describe tables\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d+ public.idx_order_*\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional considerations\n",
    "\n",
    "You can add or remove table partitions, as well as attach and detach partitions. Here are some other considerations:\n",
    "- The primary key for a partitioned table should always contain the partition key.\n",
    "- If you choose to define row triggers, you do so on individual partitions instead of the partitioned table.\n",
    "- Creating a foreign key reference on a partitioned table is not supported.\n",
    "- A partition table inherits tablespaces from its parent.\n",
    "- You cannot mix temporary and permanent relations in the same partition hierarchy.\n",
    "- If you have a default partition in the partitioning hierarchy, you can add new partitions only if there is no data in the default partition that matches the partition constraint of the new partition.\n",
    "  \n",
    "  \n",
    "To learn more about table partitioning, check out:\n",
    "\n",
    "<a href target=\"_blank\" href=\"https://docs.yugabyte.com/preview/explore/ysql-language-features/advanced-features/partitions\">Table Partitioning</a> at docs.yugabyte.com."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tablespaces and Row-level Geo-Partitioning\n",
    "YugabyteDB extends the concept of PostgreSQL tablespaces for a distributed database. In PostgreSQL, tablespaces allow administrators to specify specific tables and indexes should reside on disk, typically based on how users want to store and access the data. This control over data placement enables fine-grained performance tuning. You can, for example, place heavily accessed smaller tables and indexes on fast SSDs.\n",
    "\n",
    "YSQL tablespaces re-purpose this concept for a geo-distributed deployment by allowing you to:\n",
    "-  specify the number of replicas for a table or index,\n",
    "-  how to distribute across a set of clouds, regions, and zones\n",
    "\n",
    "Replicating and pinning tables in specific regions can lower read latency, improve resilience, and achieve compliance with data residency laws. \n",
    "\n",
    "For example, you can create duplicate indexes on the same column of a table and place these indexes close to users in different regions for fast access. Similarly, you can partition a master table and associate the partitions with different tablespaces to pin the data geographically.\n",
    "\n",
    "The ability to control the placement of tables in a fine-grained manner provides the following advantages:\n",
    "\n",
    "- Tables with critical information can have higher replication factor and increased fault tolerance compared to the rest of the data.\n",
    "- Based on the access pattern, a table can be constrained to the region or zone where it's accessed most frequently.\n",
    "- A table can have an index with an entirely different placement policy, thereby boosting the read performance without affecting the placement policy of the table itself.\n",
    "- Coupled with table partitioning, tablespaces can be used to implement row-level geo-partitioning. In other words,  based on the values of certain columns in a given row, you can pin the rows of a table to different geo-locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tablespaces are assigned repositories with assigned locations. The definition of tablespaces includes the number of replicas as well as placement blocks. Placement blocks are a cluster configuration.  Nodes in the cluster are assigned to placement blocks. Here is the configuration for this notebook\n",
    "\n",
    "` --placement_info \"cloud1.region1.zone1,cloud2.region2.zone2,cloud3.region3.zone3\" `\n",
    "\n",
    "They are arbitrarily named: cloud, region and zone.\n",
    "- `cloud1.region1.zone1`\n",
    "- `cloud2.region2.zone2`\n",
    "- `cloud3.region3.zone3`\n",
    "  \n",
    "The definition of tablespace must align with placement black names in the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists tbl_transactions;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cloud1.region1.zone1` is for the US geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" #\\d+\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "#  can't do with sql magic \n",
    "# needs double quote esacpe for bash because of JSON\n",
    "#\n",
    "# create tablespace tblspace_us with (replica_placement=\n",
    "#  '{\"num_replicas\": 1, \n",
    "#    \"placement_blocks\": [{\n",
    "#       \"cloud\": \"cloud1\", \"region\": \"region1\", \"zone\": \"zone1\", \"min_num_replicas\": 1}]\n",
    "#   }'\n",
    "# );\n",
    "DDL_TABLESPACE_US=\"drop tablespace if exists tblspace_us; create tablespace tblspace_us with (replica_placement='{\"\\\"num_replicas\"\\\": 3, \"\\\"placement_blocks\"\\\": [{ \"\\\"cloud\"\\\": \"\\\"cloud1\"\\\", \"\\\"region\"\\\": \"\\\"region1\"\\\", \"\\\"zone\"\\\": \"\\\"zone1\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud2\"\\\", \"\\\"region\"\\\": \"\\\"region2\"\\\", \"\\\"zone\"\\\": \"\\\"zone2\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud3\"\\\", \"\\\"region\"\\\": \"\\\"region3\"\\\", \"\\\"zone\"\\\": \"\\\"zone3\"\\\", \"\\\"min_num_replicas\"\\\": 1}]}');\" \n",
    "\n",
    "echo $DDL_TABLESPACE_US | ./bin/ysqlsh -d ${DB_NAME}\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cloud2.region2.zone2` is for the EU  geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" #\\d+\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "#  can't do with sql magic \n",
    "# needs double quote esacpe for bash because of JSON\n",
    "\n",
    "DDL_TABLESPACE_EU=\"drop tablespace if exists tblspace_eu; create tablespace tblspace_eu with (replica_placement='{\"\\\"num_replicas\"\\\": 3, \"\\\"placement_blocks\"\\\": [{ \"\\\"cloud\"\\\": \"\\\"cloud1\"\\\", \"\\\"region\"\\\": \"\\\"region1\"\\\", \"\\\"zone\"\\\": \"\\\"zone1\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud2\"\\\", \"\\\"region\"\\\": \"\\\"region2\"\\\", \"\\\"zone\"\\\": \"\\\"zone2\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud3\"\\\", \"\\\"region\"\\\": \"\\\"region3\"\\\", \"\\\"zone\"\\\": \"\\\"zone3\"\\\", \"\\\"min_num_replicas\"\\\": 1}]}');\" \n",
    "\n",
    "echo $DDL_TABLESPACE_EU | ./bin/ysqlsh -d ${DB_NAME}\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cloud3.region3.zone3` is for the AP geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" #\\d+\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "#  can't do with sql magic \n",
    "# needs double quote esacpe for bash because of JSON\n",
    "\n",
    "DDL_TABLESPACE_AP=\"drop tablespace if exists tblspace_ap; create tablespace tblspace_ap with (replica_placement='{\"\\\"num_replicas\"\\\": 3, \"\\\"placement_blocks\"\\\": [{ \"\\\"cloud\"\\\": \"\\\"cloud1\"\\\", \"\\\"region\"\\\": \"\\\"region1\"\\\", \"\\\"zone\"\\\": \"\\\"zone1\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud2\"\\\", \"\\\"region\"\\\": \"\\\"region2\"\\\", \"\\\"zone\"\\\": \"\\\"zone2\"\\\", \"\\\"min_num_replicas\"\\\": 1},{ \"\\\"cloud\"\\\": \"\\\"cloud3\"\\\", \"\\\"region\"\\\": \"\\\"region3\"\\\", \"\\\"zone\"\\\": \"\\\"zone3\"\\\", \"\\\"min_num_replicas\"\\\": 1}]}');\" \n",
    "\n",
    "echo $DDL_TABLESPACE_AP | ./bin/ysqlsh -d ${DB_NAME}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\db+ tblspace_*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table Partitions\n",
    "\n",
    "The partitions will determine the which rows are included with the value from `geo_location`. Since the partitioned table has the Partition property by LIST, not RANGE, only rows that contain the LIST value will be assigned to a partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists tbl_transactions;\n",
    "create table if not exists tbl_transactions (\n",
    "  user_id       int not null,\n",
    "  account_id    int not null,\n",
    "  geo_partition text,\n",
    "  account_type  text not null,\n",
    "  amount        numeric not null,\n",
    "  created_at    timestamp default now()\n",
    ") partition by list (geo_partition)\n",
    ";\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the partition for the US region with the assigned tablespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists tbl_transactions_prtn_us;\n",
    "create table tbl_transactions_prtn_us partition of tbl_transactions (\n",
    "    user_id, \n",
    "    account_id, \n",
    "    geo_partition, \n",
    "    account_type, \n",
    "    amount, \n",
    "    created_at,\n",
    "    primary key (user_id hash, account_id, geo_partition)\n",
    ") for values in ('US') \n",
    "tablespace tblspace_us;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the partition for the EU region with the assigned tablespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists tbl_transactions_prtn_eu;\n",
    "create table tbl_transactions_prtn_eu partition of tbl_transactions (\n",
    "    user_id, \n",
    "    account_id, \n",
    "    geo_partition, \n",
    "    account_type, \n",
    "    amount, \n",
    "    created_at,\n",
    "    primary key (user_id hash, account_id, geo_partition)\n",
    ") for values in ('EU') \n",
    "tablespace tblspace_eu;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the partition for the AP region with the assigned tablespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists tbl_transactions_prtn_ap;\n",
    "create table if not exists tbl_transactions_prtn_ap partition of tbl_transactions (\n",
    "    user_id, \n",
    "    account_id, \n",
    "    geo_partition, \n",
    "    account_type, \n",
    "    amount, \n",
    "    created_at,\n",
    "    primary key (user_id hash, account_id, geo_partition)\n",
    ") for values in ('AP') \n",
    "tablespace tblspace_ap;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% python, but prepared statements as sql magic\n",
    "THIS_TABLE_NAME='tbl_transactions'\n",
    "WORKSPACE_URL = MY_GITPOD_WORKSPACE_URL.replace('https://','https://7000-')\n",
    "view_url = %sql select fn_get_table_id(:WORKSPACE_URL,8200,:THIS_TABLE_NAME) as open_this_url_in_your_web_browser ;\n",
    "\n",
    "print (view_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add records to the transactions table\n",
    "Data localization also has a role in performance as well. Keeping the data source closer to the client will reduce network latency, improving the response time of the database. Having an understanding of what data is needed where coupled with the ability to place data in particular location is an important tool in distributed sql systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "insert into tbl_transactions select generate_series(1,65535), round(1000*random()), 'US', 'customer',  round(1000*random()), now();\n",
    "insert into tbl_transactions select generate_series(65536,100000), round(1000*random()), 'EU', 'customer',  round(1000*random()), now();\n",
    "insert into tbl_transactions select generate_series(100000, 150000), round(1000*random()), 'AP', 'customer',  round(1000*random()), now();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the inserts for AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select '' _\n",
    "  , tableoid::regclass\n",
    "  , user_id\n",
    "  , account_id\n",
    "  , geo_partition\n",
    "from tbl_transactions\n",
    "where 1=1\n",
    "  and geo_partition ='AP'\n",
    "-- and geo_partition ='EU'\n",
    "--  and geo_partition ='US'\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the explain plan and metrics\n",
    "\n",
    "In this example, we are using Object Identifiers to locate the partition table that is associated with the row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* explain plan */\n",
    "execute stmt_util_metrics_snap_reset;\n",
    "explain (costs off, analyze, verbose) \n",
    "select '' _\n",
    "  , tableoid::regclass\n",
    "  , user_id\n",
    "  , account_id\n",
    "  , geo_partition\n",
    "from tbl_transactions\n",
    "where 1=1 \n",
    "  and user_id = 1\n",
    "  and geo_partition = 'US'\n",
    "-- and user_id = 2\n",
    "-- and geo_partition = 'EU'\n",
    "-- and user_id = 3\n",
    "-- and geo_partition = 'AP'\n",
    "-- and yb_is_local_table(tableoid)\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Explain Plan (above ^^) and view the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "execute stmt_util_metrics_snap_table;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "# ðŸŒŸðŸŒŸðŸŒŸðŸŒŸðŸŒŸðŸŒŸ   All  done! \n",
    "In this notebook, you completed the following:\n",
    "In this lab, you completed the following:\n",
    "- Created a partitioned table consisting of table partitions\n",
    "- Created tablespaces\n",
    "- Created table partitions assigned to the tabelspaces\n",
    "- Queried the tables using row-level geo-partitioning\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
