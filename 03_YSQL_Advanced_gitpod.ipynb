{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Setup steps\n",
    "Here are the steps to setup this lab:\n",
    "- Install missing dependencies and restart the notebook\n",
    "- Create the notebook variables\n",
    "- Create Loop back IP addresses\n",
    "- Spin up cluster locally\n",
    "- Create the `db_ybu` database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install missing dependencies and restart the notebook\n",
    "Run the following cell to ensure that the notebook dependencies are available to the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql\n",
    "!pip3 install psycopg2-binary==2.8.6\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create the notebook variables \n",
    "\n",
    "> IMPORTANT!\n",
    "> \n",
    "> Do NOT skip running this cell. \n",
    "> \n",
    "\n",
    "The following Python cell creates and stores variables that all the notebooks in this lab will use. You can view these variables in the Jupyter tab.\n",
    "\n",
    "- To run the script, select Execute Cell (Play Arrow) in the left gutter of the cell.\n",
    "- Verify the accuracy of the output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/markkim/Documents/YBU_repos/jupyter/YSQL/data /Users/markkim/Documents/YBU_repos/jupyter/YSQL/utils\n",
      "Stored 'MY_DB_NAME' (str)\n",
      "Stored 'MY_YB_PATH' (str)\n",
      "Stored 'MY_GITPOD_WORKSPACE_URL' (NoneType)\n",
      "Stored 'MY_HOST_IPv4_01' (str)\n",
      "Stored 'MY_HOST_IPv4_02' (str)\n",
      "Stored 'MY_HOST_IPv4_03' (str)\n",
      "Stored 'MY_NOTEBOOK_DIR' (str)\n",
      "Stored 'MY_TSERVER_WEBSERVER_PORT' (str)\n",
      "Stored 'MY_NOTEBOOK_DATA_FOLDER' (str)\n",
      "Stored 'MY_NOTEBOOK_UTILS_FOLDER' (str)\n",
      "Stored 'MY_DATA3_DDL_FILE' (str)\n",
      "Stored 'MY_DATA3_DML_FILE' (str)\n",
      "Stored 'MY_UTIL_FUNCTIONS_FILE' (str)\n",
      "Stored 'MY_UTIL_YBTSERVER_METRICS_FILE' (str)\n"
     ]
    }
   ],
   "source": [
    "# Env variables for Notebook\n",
    "import os\n",
    "\n",
    "# read env_vars.env\n",
    "env_vars = !cat env_vars.env\n",
    "for var in env_vars:\n",
    "    key, value = var.split('=')\n",
    "    os.environ[key] = value\n",
    " \n",
    "\n",
    "# Comment out Local\n",
    "# MY_YB_PATH=os.environ.get('MY_YB_PATH_LOCAL')\n",
    "# MY_GITPOD_WORKSPACE_URL=os.environ.get('MY_GITPOD_WORKSPACE_URL_LOCAL')\n",
    "# MY_SUDO=os.environ.get('MY_SUDO')\n",
    "\n",
    "# Gitpod specific\n",
    "MY_YB_PATH=os.environ.get('MY_YB_PATH')\n",
    "MY_GITPOD_WORKSPACE_URL=os.environ.get('GITPOD_WORKSPACE_URL')\n",
    "\n",
    "# env_vars defines the following\n",
    "MY_DB_NAME=os.environ.get('MY_DB_NAME')\n",
    "MY_HOST_IPv4_01=os.environ.get('MY_HOST_IPv4_01')\n",
    "MY_HOST_IPv4_02=os.environ.get('MY_HOST_IPv4_02')\n",
    "MY_HOST_IPv4_03=os.environ.get('MY_HOST_IPv4_03')\n",
    "MY_TSERVER_WEBSERVER_PORT=os.environ.get('MY_TSERVER_WEBSERVER_PORT')\n",
    "MY_DATA3_DDL_FILE=os.environ.get('MY_DATA3_DDL_FILE')\n",
    "MY_DATA3_DML_FILE=os.environ.get('MY_DATA3_DML_FILE')\n",
    "MY_UTIL_FUNCTIONS_FILE=os.environ.get(\"MY_UTIL_FUNCTIONS_FILE\")\n",
    "MY_UTIL_YBTSERVER_METRICS_FILE=os.environ.get(\"MY_UTIL_YBTSERVER_METRICS_FILE\")\n",
    "\n",
    "# Current directory of project and related child folders\n",
    "MY_NOTEBOOK_DIR=os.getcwd()\n",
    "MY_NOTEBOOK_DATA_FOLDER=MY_NOTEBOOK_DIR +'/data'\n",
    "MY_NOTEBOOK_UTILS_FOLDER=MY_NOTEBOOK_DIR + '/utils'\n",
    "\n",
    "# Store the note book values for other notebooks to use\n",
    "%store MY_DB_NAME\n",
    "%store MY_YB_PATH\n",
    "%store MY_GITPOD_WORKSPACE_URL\n",
    "%store MY_HOST_IPv4_01\n",
    "%store MY_HOST_IPv4_02\n",
    "%store MY_HOST_IPv4_03\n",
    "%store MY_NOTEBOOK_DIR\n",
    "%store MY_TSERVER_WEBSERVER_PORT\n",
    "%store MY_NOTEBOOK_DATA_FOLDER\n",
    "%store MY_NOTEBOOK_UTILS_FOLDER\n",
    "%store MY_DATA3_DDL_FILE\n",
    "%store MY_DATA3_DML_FILE\n",
    "%store MY_UTIL_FUNCTIONS_FILE\n",
    "%store MY_UTIL_YBTSERVER_METRICS_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create the `db_ybu` database with `ysqlsh`\n",
    "Run the following cell to connect to the local host using `ysqlsh`, create the `db_ybu` database, and then list the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 4: cd: /home/gitpod/yugabyte/: No such file or directory\n",
      "bash: line 7: ./bin/ysqlsh: No such file or directory\n",
      "bash: line 8: ./bin/ysqlsh: No such file or directory\n",
      "bash: line 11: ./bin/ysqlsh: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'YB_PATH=${1}\\nDB_NAME=${2}\\n\\ncd $YB_PATH\\n\\n# drop and create\\n./bin/ysqlsh -d yugabyte -c \"drop database if exists \"${DB_NAME}\";\"  \\n./bin/ysqlsh -d yugabyte -c \"create database \"${DB_NAME}\";\" \\n\\n# list dbs\\n./bin/ysqlsh -d yugabyte -c \"\\\\l\"\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/markkim/Documents/YBU_repos/jupyter/YSQL/03_YSQL_Advanced_gitpod.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markkim/Documents/YBU_repos/jupyter/YSQL/03_YSQL_Advanced_gitpod.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mbash\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-s \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m$MY_YB_PATH\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m$MY_DB_NAME\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m  # create database\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mYB_PATH=$\u001b[39;49m\u001b[39m{1}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mDB_NAME=$\u001b[39;49m\u001b[39m{2}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mcd $YB_PATH\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# drop and create\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m./bin/ysqlsh -d yugabyte -c \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdrop database if exists \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m$\u001b[39;49m\u001b[39m{DB_NAME}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m  \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m./bin/ysqlsh -d yugabyte -c \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcreate database \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m$\u001b[39;49m\u001b[39m{DB_NAME}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# list dbs\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m./bin/ysqlsh -d yugabyte -c \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39ml\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2359\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[39m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshebang(line, cell)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'YB_PATH=${1}\\nDB_NAME=${2}\\n\\ncd $YB_PATH\\n\\n# drop and create\\n./bin/ysqlsh -d yugabyte -c \"drop database if exists \"${DB_NAME}\";\"  \\n./bin/ysqlsh -d yugabyte -c \"create database \"${DB_NAME}\";\" \\n\\n# list dbs\\n./bin/ysqlsh -d yugabyte -c \"\\\\l\"\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  # create database\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# drop and create\n",
    "./bin/ysqlsh -d yugabyte -c \"drop database if exists \"${DB_NAME}\";\"  \n",
    "./bin/ysqlsh -d yugabyte -c \"create database \"${DB_NAME}\";\" \n",
    "\n",
    "# list dbs\n",
    "./bin/ysqlsh -d yugabyte -c \"\\l\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Connect to YugabyteDB using the PostgreSQL Driver for Python\n",
    "The following cells requires:\n",
    "- Python 3.8+ and psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Create tables and loaded data using DDL and DML scripts\n",
    "In this section of the notebook, you will:\n",
    "- Create tables with a DDL script\n",
    "- Load data with a DML script\n",
    "- Verify the creation of tables and data\n",
    "- View the DDL for `order_changes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "##### Create tables, load data, and review relations\n",
    "Run the following cell to execute the DDL and DML scripts using `ysqlsh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\" \"$MY_NOTEBOOK_DATA_FOLDER\" \"$MY_DATA3_DDL_FILE\" \"$MY_DATA3_DML_FILE\"   # order_changes\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "DATA_FOLDER=${3}\n",
    "DATA_DDL_FILE=${4}\n",
    "DATA_DML_FILE=${5}\n",
    "\n",
    "ORDER_DDL_PATH=${DATA_FOLDER}/${DATA_DDL_FILE}\n",
    "ORDER_DML_PATH=${DATA_FOLDER}/${DATA_DML_FILE}\n",
    "echo $ORDER_DDL_PATH\n",
    "echo $ORDER_DML_PATH\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "# DDL file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DDL_PATH} >&/dev/null\n",
    "sleep 1;\n",
    "\n",
    "# DML file\n",
    "./bin/ysqlsh -d ${DB_NAME} -f ${ORDER_DML_PATH} >&/dev/null\n",
    "sleep 1;\n",
    "\n",
    "# Describe relations\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "##### View DDL for Table partitions\n",
    "Run the following cell using `ysqlsh` to view a table definition.\n",
    "\n",
    "> Note\n",
    "> \n",
    "> SQL magic does not support PostgreSQL `psql` commands. In order to execute `psql` commands, the notebook uses bash and `ysqlsh`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\dt\"\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_2022_02\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_2022_03\"\n",
    "# ./bin/ysqlsh -d ${DB_NAME} -c \"\\d order_changes_default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Autocommit\n",
    "\n",
    "Need to assign autocommit to true in order for DML transaction to occur without a transaction block error for the tablespace creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%config SqlMagic.autocommit=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Connect to db_ybu\n",
    "# Inspiration from https://medium.com/analytics-vidhya/postgresql-integration-with-jupyter-notebook-deb97579a38d\n",
    "import psycopg2\n",
    "import sqlalchemy as alc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# env_var.env\n",
    "db_host=MY_HOST_IPv4_01\n",
    "db_name=MY_DB_NAME\n",
    "\n",
    "connection_str='postgresql+psycopg2://yugabyte@'+db_host+':5433/'+db_name\n",
    "\n",
    "# engine = create_engine(connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Load SQL magic extension\n",
    ">IMPORTANT!\n",
    ">\n",
    "> To use SQL magic, you must run the following cell that loads the notebook extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "# creates connection for sql magic\n",
    "%sql {connection_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Show table row counts\n",
    "Run the cell below to view the row counts for the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SQL update can compute the new value and return it without the need to query again. The following adds 100 to the salaries of all employees who are not managers and show the new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM order_changes\n",
    "-- SELECT * FROM order_changes_2022_03 \n",
    "-- SELECT * FROM order_changes_2022_02 \n",
    "-- SELECT * FROM order_changes_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexed Relations\n",
    "\n",
    "By creating an index on the partitioned or parent table, a matching index is also created on any partitions that exist now or in the future. An index or unique constraint declared on a partitioned table is “virtual” in the same way that the partitioned table is: the actual data is in child indexes on the individual partition tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE INDEX ON order_changes (change_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Maintenance\n",
    "\n",
    "It is common to have a dynamic set of partitions that define a table. Partitions are frequently dropped and created to dispose of old information and add new info. \n",
    "\n",
    "Partitions simplify the removal of old data with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE order_changes_2022_02;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, a partition can be removed from the partitioned table, but still retain access to the data. This is incase a report or aggregation of the data is necessary.\n",
    "\n",
    "This is done by detaching the partition from the partitioned table with the following statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces and Geo Row Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE transactions (\n",
    "  user_id       INT NOT NULL,\n",
    "  account_id\t  INT NOT NULL,\n",
    "  geo_partition TEXT,\n",
    "  account_type  TEXT NOT NULL,\n",
    "  amount        NUMERIC NOT NULL,\n",
    "  created_at    TIMESTAMP DEFAULT NOW()\n",
    ") PARTITION BY LIST (geo_partition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tablespaces are assigned repositories with assigned locations. In our example, each tablespace is assigned to a certain node in a particular cloud, region, and zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE tblspace_us WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud1\", \"region\": \"region1\", \"zone\": \"zone1\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE  tblspace_eu WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud2\", \"region\": \"region2\", \"zone\": \"zone2\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLESPACE tblspace_ap WITH (replica_placement='{\"num_replicas\": 1, \"placement_blocks\": [{\"cloud\": \"cloud3\", \"region\": \"region3\", \"zone\": \"zone3\", \"min_num_replicas\": 1}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MY_YB_PATH\" \"$MY_DB_NAME\"  \n",
    "\n",
    "YB_PATH=${1}\n",
    "DB_NAME=${2}\n",
    "\n",
    "cd $YB_PATH\n",
    "\n",
    "./bin/ysqlsh -d ${DB_NAME} -c \"\\db+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table Partitions\n",
    "\n",
    "The partitions will determine the which rows are included with the value from `geo_location`. Since the partitioned table has the Partition property by LIST, not RANGE, only rows that contain the LIST value will be assigned to a partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Table Reads */\n",
    "\n",
    "CREATE TABLE transactions_us PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('US') TABLESPACE tblspace_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Table Reads */\n",
    "\n",
    "CREATE TABLE transactions_eu PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('EU') TABLESPACE tblspace_eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql /* Table Reads */\n",
    "\n",
    "CREATE TABLE transactions_ap PARTITION OF transactions\n",
    "    (user_id, account_id, geo_partition, account_type, amount, created_at,\n",
    "    PRIMARY KEY (user_id HASH, account_id, geo_partition))\n",
    "  FOR VALUES IN ('India') TABLESPACE tblspace_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add records to the transactions table\n",
    "\n",
    "Note that a new record is filtered by the `geo_partition` attribute to a specific table partition. Since the table partition's tablespace is assigned to a geographic location, offering data residency that complies with regulatory requirements imposed on data based on the data laws that govern a country or region in which the data resides. For example think about the user data stored at Tik Tok and the regulatory standards that prevents that data being stored outside this country's boundaries.\n",
    "\n",
    "Data localization also has a role in performance as well. Keeping the data source closer to the client will reduce network latency, improving the response time of the database. Having an understanding of what data is needed where coupled with the ability to place data in particular location is an important tool in distributed sql systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO transactions  VALUES (1, 100, 'US', 'customer', 100, now())\n",
    "-- INSERT INTO transactions  VALUES (2, 200, 'EU', 'customer', 200, now())\n",
    "-- INSERT INTO transactions  VALUES (3, 300, 'India', 'customer', 300, now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate SQL operations\n",
    "\n",
    "Review the rows to compare how the `geo_location` attribute determines the table partition. In this case, we set the location of the tablespace, then assigned a partition with a specific value for the `geo_location` attribute to determine which row will be assigned to the tablespace. This is geo row location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM transactions\n",
    "-- SELECT * FROM transactions_us\n",
    "-- SELECT * FROM transactions_eu\n",
    "-- SELECT * FROM transactions_ap\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition FROM transactions\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition  FROM transactions_us\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition FROM transactions_eu\n",
    "-- SELECT tableoid::regclass, user_id, account_id, geo_partition  FROM transactions_ap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Identifiers\n",
    "\n",
    "In this example, we are using Object Identifiers to locate the partition table that is associated with the row of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "# All done!\n",
    "In this lab, you completed the following:\n",
    "\n",
    "- Setup\n",
    "  - Created the `db_ybu` database with `ysqlsh`\n",
    "  - Created tables and loaded data using DDL and DML scripts\n",
    "  - Connected to the database using a PostgreSQL driver for Python\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3.9.4': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0857ffcb80af2fb548f76c195b67e2e5b75e102946b97bbf401092901016b64a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
